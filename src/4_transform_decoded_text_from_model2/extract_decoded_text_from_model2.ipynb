{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98d61d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Author]: Jun Yao\n",
    "# [Date]: 2021-12-03\n",
    "\n",
    "# [Description] \n",
    "# this file transformed decoded text(transcript) from model 2, it will be used as test data in model 1\n",
    "# as a comparison to text created from the official transcript.\n",
    "\n",
    "# [Instructions] \n",
    "# decoded text is stored in the log files of tri3 model from kaldi.\n",
    "# so log files from model 2 is needed to do this transformation.\n",
    "# the author copied the log files into the same folder where this script sits\n",
    "\n",
    "# input of this script:\n",
    "# ./log/decode.*.log\n",
    "# tedlium3_topic_labels.csv\n",
    "\n",
    "# output of this script:\n",
    "# test_text_from_model2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9457d4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>URI</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>UPLOAD_DATE</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>TOPIC1</th>\n",
       "      <th>TOPIC2</th>\n",
       "      <th>TOPIC3</th>\n",
       "      <th>TRANSCRIPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>911Mothers_2010W.stm</td>\n",
       "      <td>/talks/aicha_el_wafi_phyllis_rodriguez_the_mot...</td>\n",
       "      <td>The mothers who found forgiveness, friendship</td>\n",
       "      <td>Aicha el-Wafi + Phyllis Rodriguez</td>\n",
       "      <td>2011-05-02</td>\n",
       "      <td>9M54S</td>\n",
       "      <td>culture</td>\n",
       "      <td>global issues</td>\n",
       "      <td>parenting</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AalaElKhani_2016X.stm</td>\n",
       "      <td>/talks/aala_el_khani_what_it_s_like_to_be_a_pa...</td>\n",
       "      <td>What it's like to be a parent in a war zone</td>\n",
       "      <td>Aala El-Khani</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>14M16S</td>\n",
       "      <td>communication</td>\n",
       "      <td>community</td>\n",
       "      <td>family</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AaronHuey_2010X.stm</td>\n",
       "      <td>/talks/aaron_huey_america_s_native_prisoners_o...</td>\n",
       "      <td>America's native prisoners of war</td>\n",
       "      <td>Aaron Huey</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>15M27S</td>\n",
       "      <td>TEDx</td>\n",
       "      <td>culture</td>\n",
       "      <td>history</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AaronKoblin_2011.stm</td>\n",
       "      <td>/talks/aaron_koblin_visualizing_ourselves_with...</td>\n",
       "      <td>Visualizing ourselves ... with crowd-sourced data</td>\n",
       "      <td>Aaron Koblin</td>\n",
       "      <td>2011-05-23</td>\n",
       "      <td>18M18S</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>data</td>\n",
       "      <td>design</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AaronOConnell_2011.stm</td>\n",
       "      <td>/talks/aaron_o_connell_making_sense_of_a_visib...</td>\n",
       "      <td>Making sense of a visible quantum object</td>\n",
       "      <td>Aaron O'Connell</td>\n",
       "      <td>2011-06-02</td>\n",
       "      <td>7M51S</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>physics</td>\n",
       "      <td>science</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                FILENAME  \\\n",
       "0   1    911Mothers_2010W.stm   \n",
       "1   2   AalaElKhani_2016X.stm   \n",
       "2   3     AaronHuey_2010X.stm   \n",
       "3   4    AaronKoblin_2011.stm   \n",
       "4   5  AaronOConnell_2011.stm   \n",
       "\n",
       "                                                 URI  \\\n",
       "0  /talks/aicha_el_wafi_phyllis_rodriguez_the_mot...   \n",
       "1  /talks/aala_el_khani_what_it_s_like_to_be_a_pa...   \n",
       "2  /talks/aaron_huey_america_s_native_prisoners_o...   \n",
       "3  /talks/aaron_koblin_visualizing_ourselves_with...   \n",
       "4  /talks/aaron_o_connell_making_sense_of_a_visib...   \n",
       "\n",
       "                                               TITLE  \\\n",
       "0      The mothers who found forgiveness, friendship   \n",
       "1        What it's like to be a parent in a war zone   \n",
       "2                  America's native prisoners of war   \n",
       "3  Visualizing ourselves ... with crowd-sourced data   \n",
       "4           Making sense of a visible quantum object   \n",
       "\n",
       "                              AUTHOR UPLOAD_DATE DURATION         TOPIC1  \\\n",
       "0  Aicha el-Wafi + Phyllis Rodriguez  2011-05-02    9M54S        culture   \n",
       "1                      Aala El-Khani  2017-02-10   14M16S  communication   \n",
       "2                         Aaron Huey  2010-11-10   15M27S           TEDx   \n",
       "3                       Aaron Koblin  2011-05-23   18M18S  collaboration   \n",
       "4                    Aaron O'Connell  2011-06-02    7M51S     philosophy   \n",
       "\n",
       "          TOPIC2     TOPIC3 TRANSCRIPT  \n",
       "0  global issues  parenting             \n",
       "1      community     family             \n",
       "2        culture    history             \n",
       "3           data     design             \n",
       "4        physics    science             "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#log files come from:\n",
    "#kaldi-trunk/egs/tedlium/s5_r3/exp/tri3/decode_test/log/decode.*.log\n",
    "#they will be copied to ./log/ after kaldi training and decoding process\n",
    "\n",
    "tri3_decode_path = \"./log/\" \n",
    "\n",
    "# read gold labels file\n",
    "df = pd.read_csv(\"tedlium3_topic_labels.csv\")\n",
    "\n",
    "# add a new column to the dataframe\n",
    "df = df.assign(TRANSCRIPT=\"\")\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39cef3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====>find 38 log files:\n",
      "decode.2.log\n",
      "decode.3.log\n",
      "decode.1.log\n",
      "decode.4.log\n",
      "decode.5.log\n",
      "decode.7.log\n",
      "decode.6.log\n",
      "decode.25.log\n",
      "decode.31.log\n",
      "decode.19.log\n",
      "decode.18.log\n",
      "decode.30.log\n",
      "decode.24.log\n",
      "decode.32.log\n",
      "decode.26.log\n",
      "decode.27.log\n",
      "decode.33.log\n",
      "decode.37.log\n",
      "decode.23.log\n",
      "decode.22.log\n",
      "decode.36.log\n",
      "decode.20.log\n",
      "decode.34.log\n",
      "decode.35.log\n",
      "decode.21.log\n",
      "decode.10.log\n",
      "decode.38.log\n",
      "decode.11.log\n",
      "decode.13.log\n",
      "decode.12.log\n",
      "decode.16.log\n",
      "decode.17.log\n",
      "decode.29.log\n",
      "decode.15.log\n",
      "decode.14.log\n",
      "decode.28.log\n",
      "decode.8.log\n",
      "decode.9.log\n",
      "====>finding decoded segements in decode.2.log....\n",
      "====>decoded text from decode.2.log:\n",
      "stm file name is AimeeMullins_2009P.stm\n",
      "AimeeMullins_2009\n",
      "found\n",
      "====>finding decoded segements in decode.3.log....\n",
      "====>decoded text from decode.3.log:\n",
      "stm file name is AimeeMullins_2009P.stm\n",
      "AimeeMullins_2009\n",
      "found\n",
      "====>finding decoded segements in decode.1.log....\n",
      "====>decoded text from decode.1.log:\n",
      "stm file name is AimeeMullins_2009P.stm\n",
      "AimeeMullins_2009\n",
      "found\n",
      "====>finding decoded segements in decode.4.log....\n",
      "====>decoded text from decode.4.log:\n",
      "stm file name is AimeeMullins_2009P.stm\n",
      "AimeeMullins_2009\n",
      "found\n",
      "====>finding decoded segements in decode.5.log....\n",
      "====>decoded text from decode.5.log:\n",
      "stm file name is AimeeMullins_2009P.stm\n",
      "AimeeMullins_2009\n",
      "found\n",
      "====>finding decoded segements in decode.7.log....\n",
      "====>decoded text from decode.7.log:\n",
      "stm file name is BillGates_2010.stm\n",
      "BillGates_2010\n",
      "found\n",
      "====>finding decoded segements in decode.6.log....\n",
      "====>decoded text from decode.6.log:\n",
      "stm file name is BillGates_2010.stm\n",
      "BillGates_2010\n",
      "found\n",
      "====>finding decoded segements in decode.25.log....\n",
      "====>decoded text from decode.25.log:\n",
      "stm file name is JamesCameron_2010.stm\n",
      "JamesCameron_2010\n",
      "====>finding decoded segements in decode.31.log....\n",
      "====>decoded text from decode.31.log:\n",
      "stm file name is MichaelSpecter_2010.stm\n",
      "MichaelSpecter_2010\n",
      "====>finding decoded segements in decode.19.log....\n",
      "====>decoded text from decode.19.log:\n",
      "stm file name is DanielKahneman_2010.stm\n",
      "DanielKahneman_2010\n",
      "====>finding decoded segements in decode.18.log....\n",
      "====>decoded text from decode.18.log:\n",
      "stm file name is DanielKahneman_2010.stm\n",
      "DanielKahneman_2010\n",
      "====>finding decoded segements in decode.30.log....\n",
      "====>decoded text from decode.30.log:\n",
      "stm file name is JaneMcGonigal_2010.stm\n",
      "JaneMcGonigal_2010\n",
      "found\n",
      "====>finding decoded segements in decode.24.log....\n",
      "====>decoded text from decode.24.log:\n",
      "stm file name is JamesCameron_2010.stm\n",
      "JamesCameron_2010\n",
      "====>finding decoded segements in decode.32.log....\n",
      "====>decoded text from decode.32.log:\n",
      "stm file name is MichaelSpecter_2010.stm\n",
      "MichaelSpecter_2010\n",
      "====>finding decoded segements in decode.26.log....\n",
      "====>decoded text from decode.26.log:\n",
      "stm file name is JamesCameron_2010.stm\n",
      "JamesCameron_2010\n",
      "====>finding decoded segements in decode.27.log....\n",
      "====>decoded text from decode.27.log:\n",
      "stm file name is JaneMcGonigal_2010.stm\n",
      "JaneMcGonigal_2010\n",
      "found\n",
      "====>finding decoded segements in decode.33.log....\n",
      "====>decoded text from decode.33.log:\n",
      "stm file name is MichaelSpecter_2010.stm\n",
      "MichaelSpecter_2010\n",
      "====>finding decoded segements in decode.37.log....\n",
      "====>decoded text from decode.37.log:\n",
      "stm file name is TomWujec_2010U.stm\n",
      "TomWujec_2010\n",
      "found\n",
      "====>finding decoded segements in decode.23.log....\n",
      "====>decoded text from decode.23.log:\n",
      "stm file name is JamesCameron_2010.stm\n",
      "JamesCameron_2010\n",
      "====>finding decoded segements in decode.22.log....\n",
      "====>decoded text from decode.22.log:\n",
      "stm file name is GaryFlake_2010.stm\n",
      "GaryFlake_2010\n",
      "====>finding decoded segements in decode.36.log....\n",
      "====>decoded text from decode.36.log:\n",
      "stm file name is RobertGupta_2010U.stm\n",
      "RobertGupta_2010\n",
      "found\n",
      "====>finding decoded segements in decode.20.log....\n",
      "====>decoded text from decode.20.log:\n",
      "stm file name is EricMead_2009P.stm\n",
      "EricMead_2009\n",
      "====>finding decoded segements in decode.34.log....\n",
      "====>decoded text from decode.34.log:\n",
      "stm file name is MichaelSpecter_2010.stm\n",
      "MichaelSpecter_2010\n",
      "====>finding decoded segements in decode.35.log....\n",
      "====>decoded text from decode.35.log:\n",
      "stm file name is RobertGupta_2010U.stm\n",
      "RobertGupta_2010\n",
      "found\n",
      "====>finding decoded segements in decode.21.log....\n",
      "====>decoded text from decode.21.log:\n",
      "stm file name is EricMead_2009P.stm\n",
      "EricMead_2009\n",
      "====>finding decoded segements in decode.10.log....\n",
      "====>decoded text from decode.10.log:\n",
      "stm file name is BillGates_2010.stm\n",
      "BillGates_2010\n",
      "found\n",
      "====>finding decoded segements in decode.38.log....\n",
      "====>decoded text from decode.38.log:\n",
      "stm file name is TomWujec_2010U.stm\n",
      "TomWujec_2010\n",
      "found\n",
      "====>finding decoded segements in decode.11.log....\n",
      "====>decoded text from decode.11.log:\n",
      "stm file name is BillGates_2010.stm\n",
      "BillGates_2010\n",
      "found\n",
      "====>finding decoded segements in decode.13.log....\n",
      "====>decoded text from decode.13.log:\n",
      "stm file name is DanBarber_2010.stm\n",
      "DanBarber_2010\n",
      "found\n",
      "====>finding decoded segements in decode.12.log....\n",
      "====>decoded text from decode.12.log:\n",
      "stm file name is DanBarber_2010.stm\n",
      "DanBarber_2010\n",
      "found\n",
      "====>finding decoded segements in decode.16.log....\n",
      "====>decoded text from decode.16.log:\n",
      "stm file name is DanielKahneman_2010.stm\n",
      "DanielKahneman_2010\n",
      "====>finding decoded segements in decode.17.log....\n",
      "====>decoded text from decode.17.log:\n",
      "stm file name is DanielKahneman_2010.stm\n",
      "DanielKahneman_2010\n",
      "====>finding decoded segements in decode.29.log....\n",
      "====>decoded text from decode.29.log:\n",
      "stm file name is JaneMcGonigal_2010.stm\n",
      "JaneMcGonigal_2010\n",
      "found\n",
      "====>finding decoded segements in decode.15.log....\n",
      "====>decoded text from decode.15.log:\n",
      "stm file name is DanBarber_2010.stm\n",
      "DanBarber_2010\n",
      "found\n",
      "====>finding decoded segements in decode.14.log....\n",
      "====>decoded text from decode.14.log:\n",
      "stm file name is DanBarber_2010.stm\n",
      "DanBarber_2010\n",
      "found\n",
      "====>finding decoded segements in decode.28.log....\n",
      "====>decoded text from decode.28.log:\n",
      "stm file name is JaneMcGonigal_2010.stm\n",
      "JaneMcGonigal_2010\n",
      "found\n",
      "====>finding decoded segements in decode.8.log....\n",
      "====>decoded text from decode.8.log:\n",
      "stm file name is BillGates_2010.stm\n",
      "BillGates_2010\n",
      "found\n",
      "====>finding decoded segements in decode.9.log....\n",
      "====>decoded text from decode.9.log:\n",
      "stm file name is BillGates_2010.stm\n",
      "BillGates_2010\n",
      "found\n",
      "success\n",
      "=====>found 6 files, final dataframe is:\n",
      "        ID                 FILENAME  \\\n",
      "30      31    AimeeMullins_1998.stm   \n",
      "255    256       BillGates_2009.stm   \n",
      "464    465      DanBarber_2008P.stm   \n",
      "957    958  JaneMcGonigal_2012G.stm   \n",
      "1853  1854    RobertGupta_2012P.stm   \n",
      "2243  2244       TomWujec_2009G.stm   \n",
      "\n",
      "                                                    URI  \\\n",
      "30    /talks/aimee_mullins_changing_my_legs_and_my_m...   \n",
      "255   /talks/bill_gates_mosquitos_malaria_and_education   \n",
      "464               /talks/dan_barber_a_foie_gras_parable   \n",
      "957   /talks/jane_mcgonigal_the_game_that_can_give_y...   \n",
      "1853     /talks/robert_gupta_between_music_and_medicine   \n",
      "2243  /talks/tom_wujec_learn_to_use_the_13th_century...   \n",
      "\n",
      "                                                  TITLE          AUTHOR  \\\n",
      "30                    Changing my legs - and my mindset   Aimee Mullins   \n",
      "255                    Mosquitos, malaria and education      Bill Gates   \n",
      "464                                 A foie gras parable      Dan Barber   \n",
      "957   The game that can give you 10 extra years of life  Jane McGonigal   \n",
      "1853                         Between music and medicine    Robert Gupta   \n",
      "2243            Learn to use the 13th-century astrolabe       Tom Wujec   \n",
      "\n",
      "     UPLOAD_DATE DURATION         TOPIC1         TOPIC2         TOPIC3  \\\n",
      "30    2009-01-28   22M25S         beauty  body language         design   \n",
      "255   2009-02-05   20M16S       business      education         health   \n",
      "464   2008-11-24   20M24S  entertainment           food  global issues   \n",
      "957   2012-07-09   19M30S  body language  entertainment         gaming   \n",
      "1853  2012-10-02   16M27S    TED Fellows       activism       medicine   \n",
      "2243  2009-11-20    9M25S      astronomy        history     innovation   \n",
      "\n",
      "                                             TRANSCRIPT  \n",
      "30    . but in the previous instances of those the s...  \n",
      "255   . the temperature will continue to rise and so...  \n",
      "464   . sid what percentage. of your feed his chicke...  \n",
      "957   . recently scientists have suggested that her ...  \n",
      "1853  . and i played the first movement of the beeth...  \n",
      "2243  . several years ago here at ted peter skillman...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def read_decoded_text_from_kaldi(file_name):\n",
    "    #print(file_name)\n",
    "    full_path = tri3_decode_path + file_name\n",
    "    #print(f\"file path: {full_path}\")\n",
    "    trans_name = None\n",
    "    trans = []\n",
    "    with open(full_path) as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"LOG\"):\n",
    "                continue\n",
    "            m = re.findall(r\"\\d{7}-\\d{7}\", line)\n",
    "            if m:\n",
    "                #print(line)\n",
    "                #print(f\"find segement: {m[0]}\")\n",
    "                splitstrs = line.split(\"-\"+m[0])\n",
    "                trans_name = splitstrs[0]\n",
    "                trans.append(splitstrs[1].replace(\"<unk>\",\"\").replace(\"'\",\"\").replace(\"\\n\",\"\").strip())\n",
    "    return [trans_name,\". \".join(trans)]\n",
    "\n",
    "list_of_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(tri3_decode_path):\n",
    "    for file in files:\n",
    "        if file.startswith(\"decode.\"):\n",
    "            list_of_files.append(file)\n",
    "print(f\"====>find {len(list_of_files)} log files:\")\n",
    "for name in list_of_files:\n",
    "    print(name)\n",
    "\n",
    "df_len = len(df)\n",
    "\n",
    "# read all decoded texts\n",
    "for log_file_name in list_of_files:\n",
    "    print(f\"====>finding decoded segements in {log_file_name}....\")\n",
    "    with open(tri3_decode_path+log_file_name) as file:\n",
    "        tmp = read_decoded_text_from_kaldi(log_file_name)\n",
    "        print(f\"====>decoded text from {log_file_name}:\")\n",
    "        #print(tmp)\n",
    "        if tmp[0] is None:\n",
    "            continue\n",
    "            \n",
    "        # add transcript to df\n",
    "        fname = tmp[0]+\".stm\"\n",
    "        print(f\"stm file name is {fname}\")\n",
    "        year = tmp[0].split(\"_\")[1]\n",
    "        if len(year)>4:\n",
    "            year = year[0:4]\n",
    "        file_name_to_match = tmp[0].split(\"_\")[0]+\"_\"+str(year)\n",
    "        print(file_name_to_match)\n",
    "        for i in range(df_len):\n",
    "            #print(df.iloc[i,1])\n",
    "            if df.iloc[i,1].find(tmp[0].split(\"_\")[0])>-1:\n",
    "                print(\"found\")\n",
    "                df.iloc[i,10] = df.iloc[i,10] + \". \" + tmp[1]\n",
    "                break\n",
    "        #break\n",
    "    \n",
    "print(\"success\")\n",
    "\n",
    "filtered_df = df[df['TRANSCRIPT'] != \"\"]\n",
    "print(f\"=====>found {len(filtered_df)} files, final dataframe is:\")\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4346789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    titles                                          summaries  \\\n",
      "0    AimeeMullins_1998.stm  . but in the previous instances of those the s...   \n",
      "1       BillGates_2009.stm  . the temperature will continue to rise and so...   \n",
      "2      DanBarber_2008P.stm  . sid what percentage. of your feed his chicke...   \n",
      "3  JaneMcGonigal_2012G.stm  . recently scientists have suggested that her ...   \n",
      "4    RobertGupta_2012P.stm  . and i played the first movement of the beeth...   \n",
      "5       TomWujec_2009G.stm  . several years ago here at ted peter skillman...   \n",
      "\n",
      "                                        terms  \n",
      "0         ['beauty','body language','design']  \n",
      "1           ['business','education','health']  \n",
      "2    ['entertainment','food','global issues']  \n",
      "3  ['body language','entertainment','gaming']  \n",
      "4       ['TED Fellows','activism','medicine']  \n",
      "5        ['astronomy','history','innovation']  \n"
     ]
    }
   ],
   "source": [
    "# prepare the data for comparison in model 1\n",
    "column_names = [\"titles\", \"summaries\", \"terms\"]\n",
    "df_md_1 = pd.DataFrame(columns = column_names,index = list(range(len(filtered_df))))\n",
    "for i in range(len(filtered_df)):\n",
    "    df_md_1.iloc[i,0] = filtered_df.iloc[i,1]\n",
    "    df_md_1.iloc[i,1] = filtered_df.iloc[i,10]\n",
    "    if len(str(df.iloc[i,8]))<1:\n",
    "        df_md_1.iloc[i,2] = f\"['{filtered_df.iloc[i,7]}']\"\n",
    "    elif len(str(df.iloc[i,9]))<1:\n",
    "        df_md_1.iloc[i,2] = f\"['{filtered_df.iloc[i,7]}','{filtered_df.iloc[i,8]}']\"\n",
    "    else:\n",
    "        df_md_1.iloc[i,2] = f\"['{filtered_df.iloc[i,7]}','{filtered_df.iloc[i,8]}','{filtered_df.iloc[i,9]}']\"\n",
    "print(df_md_1[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c61627b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv file\n",
    "df_md_1.to_csv('test_text_from_model2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a99ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
